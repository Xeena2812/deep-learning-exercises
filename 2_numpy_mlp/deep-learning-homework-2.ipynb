{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xeena2812/71f3914c00cec6ea10b81e91d3262177#file-deep-learning-homework-2-ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-JYdo-gRqQuf"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorboardX import SummaryWriter\n",
        "from datetime import datetime\n",
        "from sklearn import preprocessing\n",
        "\n",
        "logdir = \"logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1ztQ-Iz5qQui"
      },
      "outputs": [],
      "source": [
        "def activation(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def dactivation(x):\n",
        "    return np.exp(-x)/(1.0 + np.exp(-x))**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x1DyXKwcqQuj"
      },
      "outputs": [],
      "source": [
        "#  (2,3,1)\n",
        "#There are reshapes of matrices, these are needed because numpy often outputs\n",
        "# (n, ) instead of (n, 1) as a result of an aoperation, but do not impact the outcome\n",
        "#\n",
        "#  The main change is at line 66 \n",
        "class MLP:\n",
        "\n",
        "    def __init__(self, *args):\n",
        "        np.random.seed(123)\n",
        "        self.shape = args\n",
        "        n = len(args)\n",
        "        \n",
        "        self.layers = []\n",
        "\n",
        "        self.layers.append(np.ones(self.shape[0]+1))\n",
        "\n",
        "        for i in range(1, n):\n",
        "            self.layers.append(np.ones(self.shape[i]))\n",
        "\n",
        "        self.weights = []\n",
        "        for i in range(n-1):\n",
        "            self.weights.append(\n",
        "                np.zeros((self.layers[i].size, self.layers[i+1].size)))\n",
        "\n",
        "        self.dw = [0, ]*len(self.weights)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        for i in range(len(self.weights)):\n",
        "            Z = np.random.random((self.weights[i].shape[0], self.weights[i].shape[1]))\n",
        "\n",
        "            self.weights[i][...] = (2*Z-1)*1\n",
        "\n",
        "    def propagate_forward(self, data):\n",
        "        data = np.append(data, [[1]] * data.shape[0], axis=1)\n",
        "        \n",
        "        self.layers[0] = data\n",
        "\n",
        "        for i in range(1, len(self.shape)):\n",
        "            s_i = np.dot(self.layers[i-1], self.weights[i-1])\n",
        "            self.layers[i] = activation(s_i).reshape(s_i.shape[0], s_i.shape[1])\n",
        "\n",
        "        return self.layers[-1]\n",
        "\n",
        "    def propagate_backward(self, target, lrate=0.1):\n",
        "        deltas = []\n",
        "        \n",
        "        target = target.reshape(-1, 1)\n",
        "        derror = -(target-self.layers[-1])\n",
        "        s_last = np.dot(self.layers[-2], self.weights[-1])\n",
        "        delta_last = derror * dactivation(s_last).reshape(s_last.shape[0], s_last.shape[1])\n",
        "        \n",
        "        deltas.append(delta_last)\n",
        "        \n",
        "        for i in range(len(self.shape)-2, 0, -1):\n",
        "            s_i = np.dot(self.layers[i-1], self.weights[i-1])\n",
        "            delta_i = np.dot(deltas[0], self.weights[i].T)\n",
        "            delta_i *= (dactivation(s_i).reshape(s_i.shape[0], s_i.shape[1]))\n",
        "            deltas.insert(0, delta_i)\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            layer = np.atleast_2d(self.layers[i])\n",
        "            delta = np.atleast_2d(deltas[i])\n",
        "            #All the differences from the batches are added up in \n",
        "            #the dot product so we need to divide by the batch size\n",
        "            dw = -lrate*np.dot(layer.T, delta) / target.shape[0]\n",
        "            self.weights[i] += dw\n",
        "            \n",
        "            self.dw[i] = dw\n",
        "\n",
        "        error = (target - self.layers[-1])**2\n",
        "\n",
        "        return error.sum()\n",
        " \n",
        "\n",
        "def learn(network, X, Y, valid_split, test_split, write, epochs=20, lrate=0.1, batch_size=1):\n",
        "\n",
        "    nb_samples = len(Y)\n",
        "    X_train = X[0:int(nb_samples*(1-valid_split-test_split))]\n",
        "    Y_train = Y[0:int(nb_samples*(1-valid_split-test_split))]\n",
        "    X_valid = X[int(nb_samples*(1-valid_split-test_split))                :int(nb_samples*(1-test_split))]\n",
        "    Y_valid = Y[int(nb_samples*(1-valid_split-test_split))                :int(nb_samples*(1-test_split))]\n",
        "    X_test = X[int(nb_samples*(1-test_split)):]\n",
        "    Y_test = Y[int(nb_samples*(1-test_split)):]\n",
        "\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_valid = scaler.fit_transform(X_valid)\n",
        "    X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "    #Also randomizing the validation and test data yields better result in validation and test error\n",
        "    randperm = np.random.permutation(len(X_train))\n",
        "    X_train, Y_train = X_train[randperm], Y_train[randperm]\n",
        "    randperm = np.random.permutation(len(X_valid))\n",
        "    X_valid, Y_valid = X_valid[randperm], Y_valid[randperm]\n",
        "    randperm = np.random.permutation(len(X_test))\n",
        "    X_test, Y_test = X_test[randperm], Y_test[randperm]\n",
        "\n",
        "    for i in range(epochs):\n",
        "        train_err = 0\n",
        "        end = X_train.shape[0] - (X_train.shape[0] % batch_size)\n",
        "        \n",
        "        for k in range(0, end, batch_size):\n",
        "            network.propagate_forward(X_train[k:k+batch_size])\n",
        "            train_err += network.propagate_backward(Y_train[k:k+batch_size], lrate)\n",
        "\n",
        "        if(X_train.shape[0] % batch_size != 0):\n",
        "            network.propagate_forward(X_train[end:])\n",
        "            train_err += network.propagate_backward(Y_train[end:], lrate)\n",
        "        \n",
        "        train_err /= X_train.shape[0]\n",
        "\n",
        "        valid_err = 0\n",
        "        o_valid = np.zeros((X_valid.shape[0], 1))\n",
        "        #Remainder in case the training data is not divisible by batch size\n",
        "        end = X_valid.shape[0] - (X_valid.shape[0] % batch_size)\n",
        "        for k in range(0, end, batch_size):\n",
        "            o_valid[k:k+batch_size] = network.propagate_forward(X_valid[k:k+batch_size])\n",
        "            valid_err += ((o_valid[k:k+batch_size]-Y_valid[k:k+batch_size])**2).sum()\n",
        "\n",
        "        if(X_valid.shape[0] % batch_size != 0):\n",
        "            o_valid[end:] = network.propagate_forward(X_valid[end:])\n",
        "            valid_err += ((o_valid[end:]-Y_valid[end:])**2).sum()\n",
        "\n",
        "        valid_err /= X_valid.shape[0]\n",
        "\n",
        "        write.add_scalar('train', scalar_value=train_err, global_step=i)\n",
        "        write.add_scalar('validation', scalar_value=valid_err, global_step=i)\n",
        "        print(\"{} epoch, train_err: {}, valid_err: {}\".format(\n",
        "            i, train_err, valid_err))\n",
        "\n",
        "    print(\"TESZT\")\n",
        "    test_err = 0\n",
        "    o_test = np.zeros((X_test.shape[0], 1))\n",
        "    end = X_test.shape[0] - (X_test.shape[0] % batch_size)\n",
        "    for k in range(0, end, batch_size):\n",
        "        o_test[k:k+batch_size] = network.propagate_forward(X_test[k:k+batch_size])\n",
        "        test_err += ((o_test[k:k+batch_size]-Y_test[k:k+batch_size])**2).sum()\n",
        "\n",
        "    if(X_test.shape[0] % batch_size != 0):\n",
        "        o_test[end:] = network.propagate_forward(X_test[end:])\n",
        "        test_err += ((o_test[end:]-Y_test[end:])**2).sum()\n",
        " \n",
        "    test_err /= X_test.shape[0]\n",
        "    print(test_err)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r2qnaVlJqQum"
      },
      "outputs": [],
      "source": [
        "network = MLP (2,10,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VKs5Sf1XqQun"
      },
      "outputs": [],
      "source": [
        "nb_samples=1000\n",
        "X = np.zeros((nb_samples,2))\n",
        "Y = np.zeros(nb_samples)\n",
        "for i in range(0,nb_samples,4):\n",
        "    noise = np.random.normal(0,1,8)\n",
        "    X[i], Y[i] = (-2+noise[0],-2+noise[1]), 0\n",
        "    X[i+1], Y[i+1] = (2+noise[2],-2+noise[3]), 1\n",
        "    X[i+2], Y[i+2] = (-2+noise[4],2+noise[5]), 1\n",
        "    X[i+3], Y[i+3] = (2+noise[6],2+noise[7]), 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zjH-vPu4qQun",
        "outputId": "8386d806-dd5f-4227-a293-23677b172541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 epoch, train_err: 0.2516715411958866, valid_err: 50.69295608356027\n",
            "1 epoch, train_err: 0.25154554746715463, valid_err: 50.66987724766405\n",
            "2 epoch, train_err: 0.2514236794440746, valid_err: 50.64761100098168\n",
            "3 epoch, train_err: 0.2513057953628182, valid_err: 50.62612966723297\n",
            "4 epoch, train_err: 0.2511917578041762, valid_err: 50.60540641831608\n",
            "5 epoch, train_err: 0.25108143359892976, valid_err: 50.58541525550812\n",
            "6 epoch, train_err: 0.25097469373228537, valid_err: 50.56613099052046\n",
            "7 epoch, train_err: 0.2508714132476767, valid_err: 50.54752922646563\n",
            "8 epoch, train_err: 0.25077147115021087, valid_err: 50.52958633878711\n",
            "9 epoch, train_err: 0.2506747503100154, valid_err: 50.51227945619965\n",
            "10 epoch, train_err: 0.25058113736571686, valid_err: 50.49558644168275\n",
            "11 epoch, train_err: 0.2504905226282642, valid_err: 50.4794858735668\n",
            "12 epoch, train_err: 0.250402799985289, valid_err: 50.463957026747096\n",
            "13 epoch, train_err: 0.25031786680617507, valid_err: 50.448979854057626\n",
            "14 epoch, train_err: 0.25023562384799497, valid_err: 50.434534967833386\n",
            "15 epoch, train_err: 0.25015597516245375, valid_err: 50.420603621686844\n",
            "16 epoch, train_err: 0.25007882800396325, valid_err: 50.40716769252116\n",
            "17 epoch, train_err: 0.25000409273895985, valid_err: 50.39420966280049\n",
            "18 epoch, train_err: 0.24993168275656147, valid_err: 50.381712603094854\n",
            "19 epoch, train_err: 0.2498615143806506, valid_err: 50.36966015491488\n",
            "20 epoch, train_err: 0.24979350678345652, valid_err: 50.35803651384984\n",
            "21 epoch, train_err: 0.24972758190070043, valid_err: 50.34682641302006\n",
            "22 epoch, train_err: 0.2496636643483573, valid_err: 50.33601510685319\n",
            "23 epoch, train_err: 0.2496016813410796, valid_err: 50.325588355192146\n",
            "24 epoch, train_err: 0.2495415626123182, valid_err: 50.31553240774072\n",
            "25 epoch, train_err: 0.24948324033617122, valid_err: 50.30583398885223\n",
            "26 epoch, train_err: 0.2494266490509806, valid_err: 50.29648028266395\n",
            "27 epoch, train_err: 0.2493717255846943, valid_err: 50.287458918580484\n",
            "28 epoch, train_err: 0.24931840898200155, valid_err: 50.27875795710649\n",
            "29 epoch, train_err: 0.24926664043324787, valid_err: 50.270365876029935\n",
            "30 epoch, train_err: 0.2492163632051274, valid_err: 50.26227155695456\n",
            "31 epoch, train_err: 0.24916752257314992, valid_err: 50.25446427218052\n",
            "32 epoch, train_err: 0.24912006575587206, valid_err: 50.24693367193104\n",
            "33 epoch, train_err: 0.24907394185088197, valid_err: 50.239669771922216\n",
            "34 epoch, train_err: 0.2490291017725215, valid_err: 50.2326629412727\n",
            "35 epoch, train_err: 0.248985498191328, valid_err: 50.22590389074938\n",
            "36 epoch, train_err: 0.24894308547517482, valid_err: 50.21938366134478\n",
            "37 epoch, train_err: 0.24890181963208843, valid_err: 50.213093613181435\n",
            "38 epoch, train_err: 0.24886165825471632, valid_err: 50.2070254147381\n",
            "39 epoch, train_err: 0.24882256046642068, valid_err: 50.201171032392686\n",
            "40 epoch, train_err: 0.2487844868689684, valid_err: 50.19552272027594\n",
            "41 epoch, train_err: 0.24874739949178962, valid_err: 50.19007301043039\n",
            "42 epoch, train_err: 0.2487112617427741, valid_err: 50.18481470326823\n",
            "43 epoch, train_err: 0.248676038360574, valid_err: 50.17974085832213\n",
            "44 epoch, train_err: 0.24864169536838257, valid_err: 50.174844785282794\n",
            "45 epoch, train_err: 0.24860820002915504, valid_err: 50.17012003531642\n",
            "46 epoch, train_err: 0.24857552080224002, valid_err: 50.16556039265635\n",
            "47 epoch, train_err: 0.24854362730138807, valid_err: 50.16115986646153\n",
            "48 epoch, train_err: 0.24851249025410457, valid_err: 50.15691268293619\n",
            "49 epoch, train_err: 0.24848208146231332, valid_err: 50.15281327770335\n",
            "50 epoch, train_err: 0.2484523737642976, valid_err: 50.14885628842639\n",
            "51 epoch, train_err: 0.24842334099788665, valid_err: 50.14503654767159\n",
            "52 epoch, train_err: 0.24839495796485292, valid_err: 50.14134907600576\n",
            "53 epoch, train_err: 0.248367200396489, valid_err: 50.1377890753221\n",
            "54 epoch, train_err: 0.24834004492033107, valid_err: 50.13435192238822\n",
            "55 epoch, train_err: 0.24831346902799692, valid_err: 50.131033162610194\n",
            "56 epoch, train_err: 0.2482874510441073, valid_err: 50.12782850400607\n",
            "57 epoch, train_err: 0.24826197009625864, valid_err: 50.12473381138333\n",
            "58 epoch, train_err: 0.24823700608601773, valid_err: 50.121745100713824\n",
            "59 epoch, train_err: 0.24821253966090695, valid_err: 50.1188585337006\n",
            "60 epoch, train_err: 0.248188552187351, valid_err: 50.116070412530846\n",
            "61 epoch, train_err: 0.24816502572455598, valid_err: 50.11337717480914\n",
            "62 epoch, train_err: 0.24814194299929215, valid_err: 50.11077538866577\n",
            "63 epoch, train_err: 0.24811928738155312, valid_err: 50.108261748034245\n",
            "64 epoch, train_err: 0.2480970428610627, valid_err: 50.10583306809327\n",
            "65 epoch, train_err: 0.24807519402460454, valid_err: 50.1034862808675\n",
            "66 epoch, train_err: 0.2480537260341469, valid_err: 50.10121843098241\n",
            "67 epoch, train_err: 0.24803262460573827, valid_err: 50.099026671568\n",
            "68 epoch, train_err: 0.24801187598914798, valid_err: 50.096908260306826\n",
            "69 epoch, train_err: 0.2479914669482285, valid_err: 50.09486055562151\n",
            "70 epoch, train_err: 0.24797138474197533, valid_err: 50.092881012997225\n",
            "71 epoch, train_err: 0.24795161710626146, valid_err: 50.09096718143461\n",
            "72 epoch, train_err: 0.2479321522362244, valid_err: 50.08911670002896\n",
            "73 epoch, train_err: 0.24791297876928403, valid_err: 50.08732729467134\n",
            "74 epoch, train_err: 0.24789408576876928, valid_err: 50.08559677486765\n",
            "75 epoch, train_err: 0.24787546270813482, valid_err: 50.08392303067149\n",
            "76 epoch, train_err: 0.24785709945574594, valid_err: 50.08230402972729\n",
            "77 epoch, train_err: 0.24783898626021364, valid_err: 50.08073781441963\n",
            "78 epoch, train_err: 0.24782111373626045, valid_err: 50.079222499125216\n",
            "79 epoch, train_err: 0.24780347285109872, valid_err: 50.077756267564254\n",
            "80 epoch, train_err: 0.24778605491130448, valid_err: 50.0763373702473\n",
            "81 epoch, train_err: 0.24776885155016862, valid_err: 50.07496412201485\n",
            "82 epoch, train_err: 0.24775185471550962, valid_err: 50.07363489966591\n",
            "83 epoch, train_err: 0.24773505665793136, valid_err: 50.072348139672876\n",
            "84 epoch, train_err: 0.24771844991951084, valid_err: 50.07110233597953\n",
            "85 epoch, train_err: 0.24770202732289973, valid_err: 50.06989603787918\n",
            "86 epoch, train_err: 0.2476857819608268, valid_err: 50.06872784797022\n",
            "87 epoch, train_err: 0.24766970718598502, valid_err: 50.06759642018641\n",
            "88 epoch, train_err: 0.24765379660129214, valid_err: 50.06650045789913\n",
            "89 epoch, train_err: 0.24763804405050857, valid_err: 50.06543871208913\n",
            "90 epoch, train_err: 0.24762244360920282, valid_err: 50.06440997958527\n",
            "91 epoch, train_err: 0.24760698957604982, valid_err: 50.063413101367885\n",
            "92 epoch, train_err: 0.2475916764644511, valid_err: 50.06244696093447\n",
            "93 epoch, train_err: 0.2475764989944658, valid_err: 50.061510482725446\n",
            "94 epoch, train_err: 0.2475614520850398, valid_err: 50.06060263060779\n",
            "95 epoch, train_err: 0.24754653084652403, valid_err: 50.059722406414636\n",
            "96 epoch, train_err: 0.2475317305734701, valid_err: 50.05886884853855\n",
            "97 epoch, train_err: 0.2475170467376938, valid_err: 50.058041030576796\n",
            "98 epoch, train_err: 0.2475024749815972, valid_err: 50.05723806002661\n",
            "99 epoch, train_err: 0.24748801111173854, valid_err: 50.056459077028585\n",
            "TESZT\n",
            "25.028027950358542\n"
          ]
        }
      ],
      "source": [
        "# a pontos időt lekérdezzük majd string-re alakítjuk\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%Y%m%d_%H-%M-%S\")\n",
        "writer = SummaryWriter(logdir+\"/\"+date_time, flush_secs=1)\n",
        "\n",
        "\n",
        "# Tanítás/Tesztelés indítása\n",
        "network.reset()\n",
        "valid_split = 0.2; test_split = 0.1\n",
        "#I cannot for the life of me figure otu whats wrong and why\n",
        "#the validation and training error increases instead of decreasing\n",
        "learn(network, X, Y, valid_split, test_split, writer, 100, lrate=0.1, batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VNVYzfsnqQuv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ],
      "source": [
        "%tensorboard --logdir logs\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
